# Workflow Hooks - Task Schema v2.0 Integration

This directory contains workflow hooks that use Task Format Schema v2.0 to parse and validate tasks dynamically.

## Overview

Hooks use the **TaskSchemaParser** to parse task management files (tasks.md) using schemas generated by the `synapse sense` command. This enables hooks to work with any task format (OpenSpec, GitHub Spec Kit, custom) without hardcoded parsing logic.

Additionally, hooks support **monorepo optimization** through git-based change detection, allowing quality checks to run only on affected packages (5-10x performance improvement).

## Hook Files

| Hook | Purpose | When It Runs |
|------|---------|--------------|
| `implementer-pre-tool-use.py` | Validate config + block work based on task states | Before implementer tool execution |
| `implementer-post-tool-use.py` | Validate config + run quality gates | After implementer tool execution |
| `verifier-post-tool-use.py` | Handle verification completion | After verifier tool execution |
| `user-prompt-reminder.sh` | Remind about task management | Before user prompts |

**Supporting Modules**:
- `validate_config.py` - Config validation logic (imported by both implementer hooks)
- `task_parser.py` - Task parsing utilities (imported by task-based hooks)
- `change_detection.py` - Git-based change detection for monorepo optimization

## Monorepo Optimization

The `implementer-post-tool-use.py` hook includes automatic optimization for monorepo projects, using git-based change detection to run quality checks only on affected packages.

### How It Works

1. **Change Detection**: Uses `git diff` to identify modified files
2. **Project Mapping**: Maps changed files to their owning projects
3. **Selective Execution**: Runs quality checks only for affected projects
4. **Safe Fallbacks**: Checks all projects if git unavailable or detection fails

### Performance Improvement

**Before (All Projects)**:
- 15 packages √ó 10 sec = 150 seconds (2.5 minutes)
- Every change: 150 seconds

**After (Affected Only)**:
- 1 package √ó 10 sec = 10 seconds
- 2 packages √ó 10 sec = 20 seconds
- **5-10x faster** for typical single-project changes

### Configuration

Add to `.synapse/config.json`:

```json
{
  "quality-config": {
    "mode": "monorepo",
    "optimization": {
      "check_affected_only": true,
      "detection_method": "uncommitted",
      "fallback_to_all": true,
      "force_check_projects": ["shared-utils", "core-lib"],
      "verbose_logging": false
    },
    "projects": {
      "backend": { /* ... */ },
      "frontend": { /* ... */ }
    }
  }
}
```

**Configuration Options**:
- `check_affected_only` (default: `true`) - Enable optimization
- `detection_method` (default: `"uncommitted"`) - Git detection method
  - `"uncommitted"` - Uncommitted changes (default)
  - `"since_main"` - Changes since origin/main
  - `"last_commit"` - Changes in last commit
  - `"staged"` - Only staged changes
  - `"all_changes"` - All changes including untracked
- `fallback_to_all` (default: `true`) - Check all projects if no changes detected
- `force_check_projects` (default: `[]`) - Projects to always check (e.g., shared libraries)
- `verbose_logging` (default: `false`) - Show detailed detection info

### Environment Variables

Override configuration at runtime:

```bash
# Force check all projects (bypass optimization)
SYNAPSE_CHECK_ALL_PROJECTS=1 <your command>

# Override detection method
SYNAPSE_DETECTION_METHOD=since_main <your command>

# Enable verbose logging
SYNAPSE_VERBOSE_DETECTION=1 <your command>

# Combine multiple overrides
SYNAPSE_VERBOSE_DETECTION=1 SYNAPSE_DETECTION_METHOD=all_changes <your command>
```

**Available Environment Variables**:
- `SYNAPSE_CHECK_ALL_PROJECTS=1` - Force check all projects, disable optimization
- `SYNAPSE_DETECTION_METHOD=<method>` - Override detection method
  - Valid values: `uncommitted`, `since_main`, `last_commit`, `staged`, `all_changes`
- `SYNAPSE_VERBOSE_DETECTION=1` - Enable verbose detection logging

### Hook Output

**Optimized Check** (some projects skipped):
```
üéØ Optimized check: 2/15 affected project(s)
   Detection: git detection (uncommitted)

üì¶ Project: backend (backend/)
------------------------------------------------------------
  üîç Running lint: cd backend && ruff check .
  ‚úÖ lint passed
  üîç Running test: cd backend && pytest
  ‚úÖ test passed

üì¶ Project: shared-utils (packages/shared-utils/)
------------------------------------------------------------
  üîç Running lint: cd packages/shared-utils && ruff check .
  ‚úÖ lint passed
```

**Full Check** (all projects):
```
üîç Full check: 15 project(s)
   Reason: no changes detected (fallback to all)

üì¶ Project: backend (backend/)
...
```

### Verbose Mode

When `verbose_logging: true` or `SYNAPSE_VERBOSE_DETECTION=1`:

```
üéØ Optimized check: 2/15 affected project(s)
   Detection: git detection (uncommitted)

Change Detection Details:
  Changed files: 8
  Files (first 10):
    - backend/src/api.py
    - backend/tests/test_api.py
    - packages/shared-utils/utils.py
    - README.md
    ... and 4 more
  Affected projects: 2/15
  Projects:
    - backend (backend/): 2 file(s)
    - shared-utils (packages/shared-utils/): 1 file(s)
  Skipped projects: 13
    - frontend
    - mobile
    ... (11 more)
```

### Safety Features

1. **Git Unavailable**: Falls back to checking all projects
2. **No Changes Detected**: Falls back to checking all projects (safety)
3. **No Projects Matched**: Falls back to checking all projects
4. **Force-Check Projects**: Always checked regardless of changes
5. **Environment Override**: `SYNAPSE_CHECK_ALL_PROJECTS=1` bypasses optimization

### Troubleshooting

**Problem**: Optimization not working
```bash
# Check if optimization is enabled
cat .synapse/config.json | grep -A5 "optimization"

# Test detection manually
python3 resources/workflows/feature-implementation/hooks/change_detection.py uncommitted

# Enable verbose logging
SYNAPSE_VERBOSE_DETECTION=1 <your command>
```

**Problem**: Wrong projects detected
```bash
# Try different detection method
SYNAPSE_DETECTION_METHOD=all_changes <your command>

# Force check all projects
SYNAPSE_CHECK_ALL_PROJECTS=1 <your command>
```

**Problem**: Shared library changes not detected
```json
{
  "optimization": {
    "force_check_projects": ["shared-utils", "core-lib"]
  }
}
```

### Best Practices

1. **Force-Check Shared Libraries**: Add shared packages to `force_check_projects`
2. **Use Verbose Mode**: Enable for debugging detection issues
3. **CI/CD**: Use `since_main` detection method in CI pipelines
4. **Safety Override**: Use `SYNAPSE_CHECK_ALL_PROJECTS=1` before releases
5. **Monitor Performance**: Track time saved by optimization

## Config Validation System

Config validation is integrated into `implementer-post-tool-use.py` to ensure `.synapse/config.json` is properly structured before running quality gates. This prevents the implementer from proceeding when:
1. Config has incompatible structure (e.g., `subprojects` instead of flat `commands`)
2. Config is missing required sections

### The Problem This Solves

**Scenario**:
1. User runs `/synapse:sense` on a monorepo project
2. `/synapse:sense` generates config with `subprojects` structure
3. Quality gate hooks expect flat `commands` structure
4. Hooks fail when trying to load quality config

**Solution**:
- `implementer-post-tool-use.py` validates config structure before loading quality config
- Hard blocks (exit 2) if config structure is invalid
- Directs user to run `/synapse:sense` to regenerate config in compatible format
- `/synapse:sense` command validates generated config before reporting success

### Validation Rules

**Structural Validation** (based on `resources/schemas/synapse-config-schema.json`):
- ‚úÖ Config must have required top-level fields: `synapse_version`, `project`, `workflows`, `settings`
- ‚úÖ If `quality-config` exists, it must have `commands` and `thresholds` sections
- ‚úÖ `commands` must be a flat object (NOT `subprojects`)
- ‚ùå Blocks if config uses monorepo `subprojects` structure
- ‚ùå Blocks if required fields are missing

### Integration Points

1. **implementer-pre-tool-use.py**: Validates config before implementer runs (fail-fast)
2. **implementer-post-tool-use.py**: Validates config when loading quality config
3. **/synapse:sense command**: Validates generated config and reports result
4. **verifier.md**: Checks for permissive quality settings (test/coverage)
5. **writer.md**: Includes mandatory quality config task for initial project setup

### Usage Example

#### Invalid Config (Monorepo Structure)
```json
{
  "quality-config": {
    "projectType": "fullstack-python-typescript",
    "subprojects": {
      "backend": {
        "commands": { "lint": "cd backend && ruff check ." },
        "thresholds": { "coverage": { "lines": 0 } }
      },
      "frontend": {
        "commands": { "lint": "cd frontend && npm run lint" },
        "thresholds": { "coverage": { "lines": 0 } }
      }
    }
  }
}
```

**Result**: Blocked with message directing user to run `/sense`

#### Valid Config (Flat Structure)
```json
{
  "quality-config": {
    "projectType": "python",
    "commands": {
      "lint": "ruff check .",
      "test": "pytest",
      "coverage": "pytest --cov"
    },
    "thresholds": {
      "coverage": {
        "statements": 80,
        "branches": 75,
        "functions": 80,
        "lines": 80
      },
      "lintLevel": "strict"
    }
  }
}
```

**Result**: Passes validation

### Integration with Quality Gates

Config validation is integrated directly into the quality gate workflow:

```
Pre-tool-use Flow:
1. implementer-pre-tool-use.py:
   a. ‚Üí validate_config_for_hooks()  (fail-fast validation)
   b. If invalid ‚Üí hard block with error
   c. If valid ‚Üí validate task state
2. [Implementer agent runs]

Post-tool-use Flow:
1. [Implementer agent completes]
2. implementer-post-tool-use.py:
   a. load_quality_config()
   b. ‚Üí validate_config_for_hooks()  (defense-in-depth validation)
   c. If invalid ‚Üí hard block with error
   d. If valid ‚Üí run quality checks (lint/test/coverage/build)
```

### Testing Validation

See `test_validate_config.py` in the project root for comprehensive validation tests:

```bash
python test_validate_config.py
```

Tests cover:
- Broken config detection (subprojects structure)
- Valid config acceptance (flat structure)
- Incomplete config rejection (missing required fields)
- Missing commands detection
- Error message formatting

## Schema Consumption Pattern

All hooks follow this standard pattern for consuming task schemas:

### 1. Load Synapse Configuration

```python
import json
import os

def load_synapse_config():
    """Load synapse configuration from .synapse/config.json"""
    config_path = ".synapse/config.json"

    if not os.path.exists(config_path):
        print("‚ö†Ô∏è Synapse config not found", file=sys.stderr)
        return None

    with open(config_path, 'r') as f:
        return json.load(f)
```

### 2. Find Active Tasks File and Schema

```python
def find_active_tasks_file(config):
    """Extract active tasks file path and schema from config"""
    if not config:
        return None, None

    workflows = config.get("third_party_workflows", {}).get("detected", [])

    for workflow in workflows:
        tasks_file = workflow.get("active_tasks_file")
        schema = workflow.get("task_format_schema")

        if tasks_file and schema:
            return tasks_file, schema

    return None, None
```

### 3. Parse Tasks with Schema

```python
from synapse_cli.parsers.task_schema_parser import (
    TaskSchemaParser,
    ParsedTask,
    SchemaValidationError
)

def parse_tasks(tasks_file_path, schema):
    """Parse tasks using schema v2.0"""
    try:
        # Validate and initialize parser
        parser = TaskSchemaParser(schema)

        # Parse all tasks from file
        parsed_tasks = parser.parse_tasks_file(tasks_file_path)

        return parsed_tasks

    except SchemaValidationError as e:
        print(f"‚ùå Schema validation failed: {e}", file=sys.stderr)
        print("üí° Run 'synapse sense' to regenerate schema", file=sys.stderr)
        return None
    except Exception as e:
        print(f"‚ùå Error parsing tasks: {e}", file=sys.stderr)
        return None
```

### 4. Use Semantic States in Business Logic

```python
def check_blocking_conditions(target_task: ParsedTask, all_tasks: List[ParsedTask]):
    """Use semantic states for clean business logic"""

    # Allow continued work on in-progress tasks
    if target_task.dev_state == "in_progress":
        return False, "Continuing in-progress task"

    # Block if other tasks are in-progress
    blocking_tasks = [
        t for t in all_tasks
        if t.task_id != target_task.task_id
        and t.dev_state == "in_progress"
    ]

    if blocking_tasks:
        return True, f"Other tasks in progress: {[t.task_id for t in blocking_tasks]}"

    # Block if tasks await QA/verification
    awaiting_qa = [
        t for t in all_tasks
        if t.dev_state == "complete"
        and (t.qa_state != "complete" or t.uv_state != "complete")
    ]

    if awaiting_qa:
        return True, f"Tasks awaiting QA: {[t.task_id for t in awaiting_qa]}"

    return False, "No blocking conditions"
```

## ParsedTask Object

The `TaskSchemaParser.parse_tasks_file()` method returns a list of `ParsedTask` objects:

```python
@dataclass
class ParsedTask:
    task_id: str                    # e.g., "T001"
    description: str                # Task description
    dev_state: str                  # "not_started" | "in_progress" | "complete"
    qa_state: str                   # "not_started" | "in_progress" | "complete"
    uv_state: str                   # "not_started" | "complete"
    keywords: List[str]             # Extracted keywords for matching
    line_number: int                # Line number in tasks file
```

### Semantic States

All status fields use **semantic states** instead of raw status strings:

| Semantic State | Raw Status Examples |
|----------------|---------------------|
| `not_started` | "Not Started", "Pending", "Todo", "Waiting" |
| `in_progress` | "In Progress", "Working", "Active", "Ongoing" |
| `complete` | "Complete", "Done", "Finished", "Passed", "Verified" |

**Benefits**:
- Works with any status value variations
- No hardcoded status string comparisons
- Format-agnostic business logic

## Error Handling Best Practices

### 1. Graceful Degradation

Always allow work when schema/config is unavailable:

```python
config = load_synapse_config()
if not config:
    print("‚ÑπÔ∏è No config - allowing work", file=sys.stderr)
    sys.exit(1)  # Exit code 1 = Allow

tasks_file, schema = find_active_tasks_file(config)
if not tasks_file:
    print("‚ÑπÔ∏è No task management - allowing work", file=sys.stderr)
    sys.exit(1)  # Exit code 1 = Allow
```

### 2. Schema Validation Errors

Catch validation errors and provide actionable feedback:

```python
try:
    parser = TaskSchemaParser(schema)
except SchemaValidationError as e:
    print(f"‚ùå Invalid schema: {e}", file=sys.stderr)
    print("üí° Run 'synapse sense --validate' to check schema", file=sys.stderr)
    print("üí° Run 'synapse sense --regenerate' to fix", file=sys.stderr)
    sys.exit(1)  # Allow with warning
```

### 3. Parsing Errors

Handle file read and parsing errors:

```python
try:
    parsed_tasks = parser.parse_tasks_file(tasks_file_path)
    if not parsed_tasks:
        print("‚ö†Ô∏è No tasks found", file=sys.stderr)
        sys.exit(1)  # Allow if no tasks
except Exception as e:
    print(f"‚ùå Parsing error: {e}", file=sys.stderr)
    print("üí° Check tasks file format", file=sys.stderr)
    sys.exit(1)  # Allow on error
```

### 4. Logging and Debugging

Use stderr for logging (stdout is reserved for hook output):

```python
import sys

# Good: Logging to stderr
print(f"üîç Analyzing task: {task_id}", file=sys.stderr)
print(f"‚úÖ Blocking check passed", file=sys.stderr)

# Bad: Logging to stdout (will be parsed as hook output)
print("Some debug info")  # Don't do this!
```

## Hook Exit Codes

Hooks communicate with Claude Code using exit codes:

| Exit Code | Meaning | Use Case |
|-----------|---------|----------|
| `0` | Success (default) | Hook completed successfully |
| `1` | Allow/Pass | Not applicable or validation passed |
| `2` | Block/Fail | Blocking condition met, prevent action |

### Example Usage

```python
# Allow work
if should_allow:
    print("‚úÖ Allowing work", file=sys.stderr)
    sys.exit(1)

# Block work
if should_block:
    output = {
        "decision": "block",
        "reason": "Task T001 is in progress"
    }
    print(json.dumps(output))  # Output to stdout
    sys.exit(2)
```

## Schema Structure Reference

### Complete Schema v2.0

```json
{
  "task_format_schema": {
    "schema_version": "2.0",
    "format_type": "markdown-checklist",
    "patterns": {
      "task_line": {
        "regex": "^\\s*-\\s*\\[([ xX])\\]\\s*-\\s*\\*\\*(?P<task_id>T\\d{3}):\\s*(?P<description>.+?)\\*\\*\\s*$",
        "groups": ["checkbox", "task_id", "description"],
        "example": "- [X] - **T001: Create database schema**"
      },
      "status_line": {
        "regex": "^\\s*-\\s*\\[([ xX])\\]\\s*-\\s*(?P<field>[^:]+):\\s*\\[(?P<status>[^\\]]+)\\]\\s*$",
        "groups": ["checkbox", "field", "status"],
        "example": "- [X] - Dev Status: [Complete]"
      }
    },
    "status_semantics": {
      "fields": ["dev", "qa", "user_verification"],
      "field_mapping": {
        "dev": ["Dev Status", "Dev", "Development Status"],
        "qa": ["QA Status", "QA", "Testing Status"],
        "user_verification": ["User Verification Status", "User Verification"]
      },
      "states": {
        "dev": {
          "not_started": ["Not Started", "Pending"],
          "in_progress": ["In Progress", "Working"],
          "complete": ["Complete", "Done"]
        }
      }
    }
  }
}
```

### Key Schema Fields

- **`schema_version`**: Always "2.0" for current version
- **`format_type`**: "markdown-checklist" | "numbered-list" | "custom"
- **`patterns`**: Regex patterns with named groups for parsing
- **`status_semantics`**: Semantic mapping for fields and states
- **`field_mapping`**: Maps semantic names to raw field variations
- **`states`**: Maps semantic states to raw status variations

## Writing New Hooks

### Template

```python
#!/usr/bin/env python3
import json
import sys
import os
from typing import List, Optional, Tuple
from synapse_cli.parsers.task_schema_parser import (
    TaskSchemaParser,
    ParsedTask,
    SchemaValidationError
)

def load_synapse_config():
    """Load synapse configuration"""
    # Implementation...
    pass

def find_active_tasks_file(config):
    """Find active tasks file and schema"""
    # Implementation...
    pass

def your_business_logic(parsed_tasks: List[ParsedTask]) -> Tuple[bool, str]:
    """
    Your hook's business logic

    Returns:
        (should_block: bool, reason: str)
    """
    # Your logic here
    return False, ""

def main():
    print("üîç Running your-hook...", file=sys.stderr)

    # 1. Load config
    config = load_synapse_config()
    if not config:
        sys.exit(1)  # Allow if no config

    # 2. Find tasks and schema
    tasks_file, schema = find_active_tasks_file(config)
    if not tasks_file or not schema:
        sys.exit(1)  # Allow if no tasks

    # 3. Parse tasks
    try:
        parser = TaskSchemaParser(schema)
        parsed_tasks = parser.parse_tasks_file(tasks_file)
    except SchemaValidationError as e:
        print(f"‚ùå Schema error: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå Parse error: {e}", file=sys.stderr)
        sys.exit(1)

    # 4. Business logic
    should_block, reason = your_business_logic(parsed_tasks)

    if should_block:
        output = {"decision": "block", "reason": reason}
        print(json.dumps(output))
        sys.exit(2)

    print("‚úÖ Hook passed", file=sys.stderr)
    sys.exit(1)

if __name__ == "__main__":
    main()
```

## Testing Hooks

### Unit Testing

Test business logic independently:

```python
def test_blocking_logic():
    # Create mock tasks
    task1 = ParsedTask(
        task_id="T001",
        description="First task",
        dev_state="in_progress",
        qa_state="not_started",
        uv_state="not_started",
        keywords=["first", "task"],
        line_number=1
    )

    # Test logic
    should_block, reason = check_blocking_conditions(task1, [task1])
    assert not should_block
```

### Integration Testing

Test with real tasks files:

```bash
# Generate schema
synapse sense

# Run hook manually
python resources/workflows/feature-implementation/hooks/implementer-pre-tool-use.py <<EOF
{
  "tool_name": "Task",
  "tool_input": {
    "subagent_type": "implementer",
    "prompt": "Implement T001"
  }
}
EOF

# Check exit code
echo $?  # 1 = allow, 2 = block
```

## Troubleshooting

### Schema Not Found

**Error**: `‚ö†Ô∏è Synapse config not found`

**Solution**:
```bash
synapse sense
```

### Schema Validation Fails

**Error**: `‚ùå Schema validation failed: Unsupported schema version`

**Solution**:
```bash
synapse sense --regenerate
```

### Tasks Not Parsing

**Error**: `‚ùå Error parsing tasks: No match for task line`

**Solutions**:
1. Check tasks file format matches schema
2. Regenerate schema: `synapse sense --regenerate`
3. Validate schema: `synapse sense --validate`

### Low Match Rate

**Warning**: `‚ö†Ô∏è Schema validation below threshold: 85% match rate`

**Solutions**:
1. Check for format inconsistencies in tasks file
2. Regenerate schema with `--regenerate`
3. Check schema metadata for confidence score

## See Also

- [Task Format Schema v2.0 Design](../../../docs/schema-v2-design.md) - Complete schema specification
- [Schema Validation Rules](../../../docs/schema-v2-validation-rules.md) - Validation details
- [Schema Migration Guide](../../../docs/schema-v2-migration-guide.md) - Migration from v0
- [Hook Integration Reference](../../../docs/phase-4-hook-integration.md) - Complete integration guide
